from models.model import Model
from tensorflow.keras import Sequential, layers, models
from tensorflow.keras.layers.experimental.preprocessing import Rescaling
from tensorflow.keras.optimizers import RMSprop, Adam

class TransferedModel(Model):
    def _define_model(self, input_shape, categories_count):
        # you have to initialize self.model to a keras model
        # load your basic model with keras's load_model function
        # freeze the weights of the loaded model to make sure the training doesn't affect them
        # (check the number of total params, trainable params and non-trainable params in your summary generated by train_transfer.py)
        # use this model by removing the last layer, adding dense layers and an output layer

        # first, load trained model:
        base_model = models.load_model('results/basic_model_10_70_percent.keras')

        # freeze all params:
        for layer in base_model.layers:
            layer.trainable = False

        # remove last layer (specialized for previous task)
        base_model = models.Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)

        # new fully connected layer
        x = layers.Flatten(name='new_flatten')(base_model.output)
        x = layers.Dense(64, activation='relu', name='new_dense_1')(x)
        x = layers.Dropout(0.5, name='new_dropout')(x)
        x = layers.Dense(1, activation='sigmoid', name='output')(x)

        self.model = models.Model(inputs=base_model.input, outputs=x)
        
        
    
    def _compile_model(self):
        self.model.compile(
            optimizer=RMSprop(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        pass
